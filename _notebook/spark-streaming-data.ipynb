{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e86a47a-7483-47e1-9f60-de4b44061b55",
   "metadata": {},
   "source": [
    "## Spark Streaming 을 위한 데이터 준비\n",
    "\n",
    "로컬 Docker 환경 내 Kafka Broker 와 Zookeeper 를 가정합니다.\n",
    "\n",
    "https://github.com/1ambda/practical-data-pipeline-code 레포지토리 루트에서 아래 커맨드를 이용할 수 있습니다.\n",
    "\n",
    "```bash\n",
    "make compose.clean compose.storage-all\n",
    "```\n",
    "\n",
    "만약 Kafka Python Library 가 깔려있지 않을 경우 아래와 같이 Pyenv 환경 내에서 설치할 수 있습니다.\n",
    "\n",
    "```bash\n",
    "pyenv activate {PYENV_NAME} # 본인이 생성한 Pyenv 이름 설정\n",
    "pip install kafka-python==2.0.2\n",
    "pip install msgpack==1.0.3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5101e36c-d1da-4020-9ffa-1dbf56082699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "from kafka import KafkaConsumer\n",
    "from kafka.client_async import KafkaClient\n",
    "from kafka.admin import KafkaAdminClient, NewTopic\n",
    "from kafka import TopicPartition\n",
    "\n",
    "import json\n",
    "import msgpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e750c7fd-53f4-4adb-bad4-34c2eb2c5f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "zookeeper_servers = [\"127.0.0.1:2181\"]\n",
    "bootstrap_servers = [\"127.0.0.1:9092\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872bdf05-3d12-4cfa-b490-b8100dc388c2",
   "metadata": {},
   "source": [
    "### Topic 생성\n",
    "\n",
    "Kafka Partition 을 생성합니다. 일반적으로는 Kafka 관리자가 요청을 받아 UI 나 Console 에서 직접 생성할 수 있습니다.  \n",
    "API 를 이용해 생성하는 경우는 많지 않으나, 이 노트북에선 실습을 위해 API 를 통해 생성하는 예제를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef4be90d-e489-4da7-be95-e88987028cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "admin = KafkaAdminClient(bootstrap_servers=bootstrap_servers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "986e0139-e3aa-4a80-8411-27c4793aa189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition = 3, replication = 1 설정을 가진 토픽을 생성합니다.\n",
    "topic = \"user-event\"\n",
    "admin.create_topics([NewTopic(topic, 3, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f31c624-396d-4e86-b3b9-c01a4cbcc300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user-event', '_schemas', '__consumer_offsets']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admin.list_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aecb575-9e5c-451f-9fa5-3a3e17b84258",
   "metadata": {},
   "source": [
    "### Kafka Producer 를 이용해 데이터 전송\n",
    "\n",
    "kafka-python API 를 이용해 데이터를 Broker 로 전송합니다.  \n",
    "일반적으로는 Java / Scala 언어로 이루어진 개발한 Producer 나 Kafka Connect 등을 이용합니다.  \n",
    "\n",
    "다만 이 노트북에선 실습으로 Python API 를 이용하기 위해 Pandas 로 CSV 파일을 읽어 Python Kafka API 로 전송합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13f7f91f-d3fc-4461-9fd9-c03e19ada426",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=bootstrap_servers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dba0945a-4a70-4b7c-91bd-d1e2624778c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"/Users/hoon.park/github/1ambda/practical-data-pipeline-code\"\n",
    "DATASET_AIRBNB_LISTING = f\"{DATASET_ROOT}/_datasets/ecommerce/e-commerce.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "901c06ea-79e6-4008-bdbc-ad1ae07f6404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pdf = pd.read_csv(DATASET_AIRBNB_LISTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "538434ac-1aad-4081-8d37-3567beaf9668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_code</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:00:00 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>5809910</td>\n",
       "      <td>1602943681873052386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grattol</td>\n",
       "      <td>5.24</td>\n",
       "      <td>595414620</td>\n",
       "      <td>4adb70bb-edbd-4981-b60f-a05bfd32683a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 00:00:09 UTC</td>\n",
       "      <td>view</td>\n",
       "      <td>5812943</td>\n",
       "      <td>1487580012121948301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kinetics</td>\n",
       "      <td>3.97</td>\n",
       "      <td>595414640</td>\n",
       "      <td>c8c5205d-be43-4f1d-aa56-4828b8151c8a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                event_time event_type  product_id          category_id  \\\n",
       "0  2020-01-01 00:00:00 UTC       view     5809910  1602943681873052386   \n",
       "1  2020-01-01 00:00:09 UTC       view     5812943  1487580012121948301   \n",
       "\n",
       "  category_code     brand  price    user_id  \\\n",
       "0           NaN   grattol   5.24  595414620   \n",
       "1           NaN  kinetics   3.97  595414640   \n",
       "\n",
       "                           user_session  \n",
       "0  4adb70bb-edbd-4981-b60f-a05bfd32683a  \n",
       "1  c8c5205d-be43-4f1d-aa56-4828b8151c8a  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "561ce6c6-871f-40b6-a204-a4e4dc4d79c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Row 는 Tuple 입니다. 이를 Dict 로 바꾸기 위해 to_dict 함수를 호출해\n",
    "# 전달 받은 Row (Dict) 를 Kafka Producer 를 이용해 Topic 으로 보냅니다.\n",
    "\n",
    "for row in pdf.head(50000).to_dict(orient=\"records\"):\n",
    "    # producer.send(topicAirbnbListing, bytes(str(row), 'utf-8'))\n",
    "    del row['category_id']\n",
    "    del row['category_code']\n",
    "    del row['brand']\n",
    "    del row['user_session']\n",
    "    message = json.dumps(row).encode('utf-8')\n",
    "\n",
    "    producer.send(topic, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cf3cc4-1739-4a4a-8a57-3cb816c25ff3",
   "metadata": {},
   "source": [
    "### Console Consumer 로 데이터 읽기\n",
    "\n",
    "\n",
    "이제 Broker 에 접근해 Console Consumer 로 해당 토픽 데이터를 읽어봅니다. 컨테이너에 들어가 다음 커맨드를 실행할 수 있습니다.  \n",
    "\n",
    "```\n",
    "# 터미널에서 도커로 로그인하기 위해 `docker exec -it broker /bin/bash`\n",
    "\n",
    "kafka-console-consumer --bootstrap-server broker:9092 --topic user-event --from-beginning\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e17439-1b39-44c1-b83b-e4eaeee7906f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
